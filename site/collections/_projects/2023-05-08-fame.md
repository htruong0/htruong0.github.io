---
date: 2023-05-08
title: >
    FAME: a factorisation-aware matrix element emulator
subtitle: Particle Physics, Machine Learning
image: '/images/fame_particletracks.jpg'
---
The Large Hadron Collider (LHC) is an international high energy particle collider, operating
at CERN, deep underground between the French-Swiss border.
In order to test our theoretical model of nature, the Standard Model, we make use of simulated
particle collision events in order to match those recorded in real life as closely as possible.

Simulating events is a procedure involving a long chain of many stages. One of the key steps
is the evaluation of the actual scattering of particles embedded in what we call the matrix element.
Traditional methods to compute this quantity, while sophisticated in technique, are
computationally expensive and so are a time bottleneck. As an example, some of the collisions I worked on took around a minute to evaluate. This accumulates extremely rapidly when you require a billion simulated events to match the sample size of the experiment.

My thesis was focused on applying deep neural networks to build an emulator for these matrix elements in order to boost the rate at which we can generate simulated events. The key idea was to combine our from-first-principles knowledge of the structure of matrix elements, with the rapid advancements in machine learning. As a proof of concept, I <strong>published two papers</strong> <a href="https://arxiv.org/abs/2107.06625" target="_blank" rel="noopener noreferrer">[1]</a><a href="https://arxiv.org/abs/2302.04005" target="_blank" rel="noopener noreferrer">[2]</a> showing the viability of this method. For this work <strong>I was invited to speak at</strong> <a href="https://indico.cern.ch/event/1106990/contributions/4997201/" target="_blank" rel="noopener noreferrer">ACAT 2022</a> -- the 21st International Workshop on Advanced Computing and Analysis Techniques in Physics Research.

<em>
    For the particles physicists: these proof of concept papers were for electron-positron annihilation into up to 5 jets at tree-level and one-loop level. We exploit the factorisation property of matrix elements in soft and collinear limits, and utilise Catani-Seymour dipole functions/antenna functions, as a set of 'basis' functions to circumvent the neural network having to model these singular structures. In doing so, the neural network models a set of coefficients that are non-divergent and are well-behaved across the entirety of the sampled phase-space.
</em>

![NN architecture](/images/fame_nn.png)
*The factorisation-aware model architecture*

Since we exploit the factorisation property of matrix elements, we dub this the <strong>factorisation-aware</strong> model.
We showed that with this new method, we were able to achieve <strong>1% levels of accuracy</strong> in the emulation model whilst <strong>speeding up evaluation of matrix elements by up to 10000 times</strong> for the most complicated cases.

![NN hexplot](/images/fame_hexplot.png)
*Prediction accuracy: bulk of the points are in yellow bins with very low error*

This work relied on extensive use of the <strong>Python</strong> machine learning ecosystem to bring the model to fruition. In particular, the model was built using the <strong>TensorFlow framework with the Keras front end</strong>, where I wrote custom code to construct the <em>factorisation-aware</em> architecture. Additionally, the software to generate the datasets required for model training and testing were written from the ground up, leveraging <strong>NumPy, multiprocessing, scikit-learn</strong>, to name just a few packages.

The code for these projects can be found on my GitHub:
<div class="github-card" data-github="htruong0/fame_antenna" data-width="768" data-height="" data-theme="default"></div>
<script src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script>

The viability of embedding this neural network model into a real production environment was studied in the article <a href="https://arxiv.org/abs/2301.13562" target="_blank" rel="noopener noreferrer">[3]</a> where I extended the model for the types of collisions actually being studied at the LHC. The key takeaway points from this study were that the flexibility of the model architecture allowed me to readily adapt the code for the new scenario, and that there was a <strong>speed-up of up to 350 times</strong> in generating simulated events for the most computationally expensive case we studied!
To achieve these speed-ups, we made use of the <strong>C++ interface to the ONNX runtime</strong> which was much more performant, speedwise, compared to TensorFlow's inference interface.

![NN barchart](/images/fame_pp_bars.png)
*Effective speed-up of factorisation-aware model labelled as 'dipole' compared to a simple neural network labelled as 'naive'.*

# Publications
1. <a href="https://arxiv.org/abs/2107.06625" target="_blank" rel="noopener noreferrer">A factorisation-aware Matrix element emulator</a>
2. <a href="https://arxiv.org/abs/2302.04005" target="_blank" rel="noopener noreferrer">One-loop matrix element emulation with factorisation awareness</a>
3. <a href="https://arxiv.org/abs/2301.13562" target="_blank" rel="noopener noreferrer">Unweighting multijet event generation using factorisation-aware neural networks</a>
